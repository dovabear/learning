========================安裝========================
sudo apt-get update

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

echo $(lsb_release -cs)

sudo add-apt-repository "deb [arch=amd64]  https://download.docker.com/linux/ubuntu  xenial  stable"

sudo  apt-get update

sudo  apt-get  install  docker-ce

sudo  usermod  -aG  docker master

-------------------
sudo passwd root 
-------------------

sudo  reboot
========================Basic========================
看版本
docker --version

看docker資訊
docker info

搜尋網路上的image檔
docker search busybox

從網路拉下image檔
docker pull busybox

看本機的image檔有哪些
docker images

run一個docker
docker run --name busybox -it busybox /bin/sh

ctl+p & ctl+q退出 原docker繼續執行

看本機的container以及是否在執行
docker ps -a

已有container，再把它run起來
docker start mysh

已執行的docker，把它關掉
docker stop mysh

進入已在背景執行的docker
docker attach mysh

移除container
docker rm mysh

移除image
docker rmi mysh

看image檔的歷史紀錄命令
docker history myhp

進入docker執行命令
docker exec -it myuser whoami

container的備份與還原
docker export mybak > myexport.tar
cat myexport.tar | docker import - mythree

image的備份與還原
docker save mytwo > mysave.tar
docker load < mysave.tar

掛載硬碟
docker run --name mynginx -v /var/log/nginx/ -it nginx  /bin/bash

========================Network========================
Docker Network 橋接器
docker network create <net_name>

docker network create mynet1
docker network create mynet2

查看Docker Network
docker network ls

Add Container Docker Network
docker  network  connect  <net_name>  <container_name>

========================Ambari Installation========================
docker run --hostname=s01 --add-host master:X.X.X.X --add-host s02:X.X.X.X --add-host s03:X.X.X.X --name=s01 -itd ubuntu:16.04
docker run --hostname=s02 --add-host master:X.X.X.X --add-host s01:X.X.X.X --add-host s03:X.X.X.X --name=s02 -itd ubuntu:16.04
docker run --hostname=s03 --add-host master:X.X.X.X --add-host s01:X.X.X.X --add-host s02:X.X.X.X --name=s03 -itd ubuntu:16.04
==install ifconfig==
apt-get update
apt-get install net-tools

==install ping==
apt-get install iputils-ping

==install vi/vim==
sudo apt-get install vim

==install ssh==
sudo apt-get install ssh

==install all by one cmd==
docker exec -it s01 apt-get install iputils-ping nano net-tools ssh

==edit host/ip==
sudo vi /etc/hosts
*add following lines*

172.17.0.2 s01
172.17.0.3 s02
172.17.0.4 s03

==Firewall Off==
ufw disable
(problems with container)

==Ambari Repository Installation==
https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.6.1

==ssh==
master給root密碼
切換到root帳號
ssh-keygen
ls ~/.ssh/
 id_rsa  
 id_rsa.pub

切換到slave1，slave2
給root密碼
nano /etc/ssh/sshd_config
 PermitRootLogin without-password
 change to
 PermitRootLogin yes
service ssh restart

切換到master root帳號
ssh-copy-id -i ~/.ssh/id_rsa.pub slave1
ssh-copy-id -i ~/.ssh/id_rsa.pub slave2

各別ssh一次 因為第一次要打密碼
ssh登入 用exit離開 不是docker

去slave1 slave2 slave3 nano .bashrc檔
在最後一段加上
service ssh start

==java==
sudo apt-get install openjdk-8-jdk
export JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64/jre/bin"

==tommy command==
docker run --hostname=master --add-host slave1:172.17.0.3 --add-host slave2:172.17.0.4 --name=master -itd itaipei/sample
docker run --hostname=slave1 --add-host master:172.17.0.2 --add-host slave2:172.17.0.4 --name=slave1 -itd itaipei/sample
docker run --hostname=slave2 --add-host master:172.17.0.2 --add-host slave1:172.17.0.3 --name=slave2 -itd itaipei/sample


172.17.0.2 master
172.17.0.3 slave1
172.17.0.4 slave2

ssh-copy-id -i ~/.ssh/id_rsa.pub master
ssh-copy-id -i ~/.ssh/id_rsa.pub slave1
ssh-copy-id -i ~/.ssh/id_rsa.pub slave2

==手動安裝==
cd /opt
wget http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz
tar -zxvf hadoop-2.9.0.tar.gz
檢視相容性 file /opt/hadoop-2.9.0/lib/native/libhadoop.so.1.0.0

nano /opt/allhadoop.sh
#/bin/bash

export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/opt/hadoop-2.9.0
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

nano ~/.bashrc
source /opt/allhadoop.sh

source ~/.bashrc


一、設定hdfs
1.設定core-site.xml
nano /opt/hadoop-2.9.0/etc/hadoop/core-site.xml
<property>
<name>fs.defaultFS</name>
<value>hdfs://master:8020</value>
</property>

2.設定hdfs-site.xml
nano /opt/hadoop-2.9.0/etc/hadoop/hdfs-site.xml
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/root/nn</value>
</property>
<property>
<name>dfs.permissions.supergroup</name>
<value>root</value>
</property>
-------------------------------
<property>
<name>dfs.datanode.data.dir</name>
<value>/root/dn</value>
</property>
-------------------------------


3.設定hadoop-env.sh
nano /opt/hadoop-2.9.0/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HEAPSIZE=128
export HADOOP_NAMENODE_INIT_HEAPSIZE="128"
export HADOOP_CLIENT_OPTS="-Xmx128m $HADOOP_CLIENT_OPTS"
export HADOOP_LOG_DIR=/tmp
-----------------------------------
export HADOOP_DATANODE_OPTS="-Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS -client"
-----------------------------------


全部重開
在nanenode
hdfs namenode -format
hadoop-daemon.sh start namenode
hadoop-daemon.sh start secondarynamenode
在datanode
hadoop=daemon.sh start datanode

hdfs dfsadmin -report
